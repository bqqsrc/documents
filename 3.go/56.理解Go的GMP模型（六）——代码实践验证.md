理解Go的GMP模型（三）——GMP调度信息分析工具
===

- 作者：晓白齐齐
- 更新：2024.1.12
- 声明：本文用于记录作者学习过程的心得理解，限于作者水平有限，可能存在理解错误，欢迎提出。参考文档一栏列出了本文参考的文档，本文的一些图表来自这些参考文档，如有侵权，联系作者删除，还请见谅。<font color="red">为避免转载导致的文章质量下降，本文禁止转载。</font>

---
## 一、 GMP 的调度分析工具
可以通过两种方式可以查看程序的 GMP 数据：
1. Debug trace
2. go tool trace 

### 1. 使用 Debug trace 
1. 第一步：创建项目，编写代码。
	
	trace.go ：

	```
	package main

	import (
	    "fmt"
	    "time"
	)

	func main() {
	    for i := 0; i < 5; i++ {
	        time.Sleep(time.Second)
	        fmt.Println("Hello World")
	    }
	}
	```

2. 第二步：编译。

	```
	$ go build trace.go
	```

3. 第三步：通过 Debug 方式运行。

	```
	$ GODEBUG=schedtrace=1000 ./trace2 
	SCHED 0ms: gomaxprocs=2 idleprocs=0 threads=4 spinningthreads=1 idlethreads=1 runqueue=0 [0 0]
	Hello World
	SCHED 1003ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]
	Hello World
	SCHED 2014ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]
	Hello World
	SCHED 3015ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]
	Hello World
	SCHED 4023ms: gomaxprocs=2 idleprocs=2 threads=4 spinningthreads=0 idlethreads=2 runqueue=0 [0 0]
	Hello World
	```
	
	以上日志的意义：
	- SCHED：调试信息输出标志字符串，代表本行是 goroutine 调度器的输出；
	- 0ms：即从程序启动到输出这行日志的时间；
	- gomaxprocs: P 的数量，本例一开始有4个 P ，后设置为 2 个 P, 因为默认的 P 的属性是和 cpu 核心数量默认一致，也可以通过 GOMAXPROCS 来设置；
	- idleprocs: 处于 idle 状态的 P 的数量；通过 gomaxprocs 和 idleprocs 的差值，就可知道执行 go 代码的 P 的数量；
	- threads: os threads/M 的数量，包含 scheduler 使用的 m 数量，加上 runtime 自用的类似 sysmon 这样的 thread 的数量；
	- spinningthreads: 处于自旋状态的 os thread 数量；
	- idlethread: 处于 idle 状态的 os thread 的数量；
	- runqueue=0： Scheduler 全局队列中 G 的数量；
	- [[1 0]]: 分别为 2 个 P 的本地队列中的 G 的数量。





本节不专门讲解用 Debug trace 方法查看 GMP 数据的过程，因为作者在本文的第五节的验证过程中写了，不在这里重复写，读者可以跟着第五节一起敲下代码，相信应该就清楚如何使用了。读者也可以阅读[这篇文章](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/godebug-sched#godebug)了解。

### 2. go tool trace 的使用
本节简单介绍一下 trace 的使用，实际上 trace 能看的信息很多，读者可以阅读[这篇文章](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace)学习更多使用 trace 的使用。

1. 第一步：创建项目，编写代码，调用 trace.Start ，将trace 数据保存到文件。

2. 第二步：运行程序。

3. 第三步：打开记录轨迹的文件（假设文件名为 trace.out ）。

   trace.out 文件记录了程序运行过程中 GMP 可视化的数据，这个文件是个二进制文件，可以使用 go tool trace 打开分析：
   
   ```
   $ go tool trace trace.out
   2024/01/10 19:13:26 Parsing trace...
   2024/01/10 19:13:26 Splitting trace...
   2024/01/10 19:13:26 Opening browser. Trace viewer is listening on http://127.0.0.1:10966 
   ```

   此时可以通过打开浏览器 ```http://127.0.0.1:10966``` 网址，点击 ```view trace``` 查看程序的 GMP 调度流程，网址的端口不是固定的，在运行 ```go tool trace trace.out``` 输出的最后一行可以看到。

   可以看到 GMP 调度可视化图：
   
   <center><img src=./source/52/5.GMP可视化界面.png width=1200 float=center>

   图5. GMP可视化界面</center>

   点击右上角的 ```Flow events``` 按钮，勾选 All ，可以显示发生的事件。如下图所示：
   
   <center><img src=./source/52/6.可视化界面显示event.png width=400 float=center>

   图6. 可视化界面显示event</center>

4. 第四步：了解可视化 GMP 信息界面的使用。
   
   可视化界面的 x 轴表示程序启动运行的时间， y 轴为各项 GMP 数据。

   <center><img src=./source/52/7.GMP可视化x.y轴.png width=600 float=center>

   图7. GMP可视化x.y轴</center>

   在界面的右方有一个工具栏，可以用于缩放坐标轴的比例、移动坐标轴、选择某一范围。

   <center><img src=./source/52/8.GMP可视化工具栏.png width=500 float=center>

   图8. GMP可视化工具栏</center>

---
## 六、GMP 模型分析过程中的代码验证
本节主要为作者自己进行的验证，读者可以直接跳过，也可以跟着一起敲下代码。完整代码在本文的附录中可以获取。

### （一）验证 P 和 M 的个数和创建时机
1. 第一步： 创建一个项目，运行下面的代码：

   文件 trace.go :
   ```
   package main
   
   import (
   	"fmt"
   	"runtime"
   )
   
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(0)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   }
   ```
   
   运行：
   ```
   $ go run trace.go
   CPU 核心数量：  8
   Processor 处理器数量：  8
   ```
   
   这段代码调用 runtime.NumCPU() 输出了机器的 CPU 核心数，调用 runtime.GOMAXPROCS(0) 获取 P 的数量。通过结果可知没有设置 GOMAXPROCS 的值时默认 P 的数量为 CPU 核心数。
   
   这里的 CPU 核心数量是指机器的逻辑处理器的数量，而不是物理内核数，windows 系统下可以在 任务管理器->性能->CPU 查看到自己机器的内核数和逻辑处理器数量，这里不展开。

2. 第二步： 添加环境变量。
   给机器添加一个环境变量 GOMAXPROCS ，设置为 4 ，环境变量如何设置这里不展开，再运行程序：
   ```
   go run trace.go
   CPU 核心数量：  8
   Processor 处理器数量：  4
   ```
   
   此时 P 的数量变为 4 ，虽然 CPU 核心数量为 8 。
   
3. 第三步：GOMAXPROCS 设置具体 P数量。
   将 runtime.GOMAXPROCS(0) 改为 runtime.GOMAXPROCS(2)，运行程序，得到的结果还是4。一开始作者以为是优先取环境变量 GOMAXPROCS ，所以将环境变量删除，再运行，得到的结果是 8 ，调试之后发现 runtime.GOMAXPROCS() 传入的 n 直接就是 0 ，而不是传入的 2 。经过多番调试都没有得到理论上的 0 。作者以为是系统环境问题，便搭建了一个 Docker 环境测试，结果也不符合预期。
   
   作者起初也百思不得其解，认为是机器问题吧，到后面的步骤之后，才解了这个谜团。

4. 第四步：创建n一个长时间执行的协程。
   添加如下代码：
   ```
   func routineSum(n int) int {
   	sum := 0
   	for i := 0; i < n*10000000000; i++ {
   		sum += i
   	}
   	return sum
   }
   ```

   这个函数进行上百亿次加法运算，有一定的耗时。

   main 函数中启动 n 个协程：
   ```
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(2)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   	for i := 0; i < 5; i++ {
   		go routineSum(i)
   	}
      time.Sleep(time.Duration(5) * time.Second)
   }
   ```

   这段代码将会启动 5 个耗时较长的计算，并且主线程休眠 5 秒。

5. 第五步：使用 Debug trace 来查看 P 和 M 的情况。

   编译:
   ```
   $ go build trace.go 
   ```

   通过 Debug 方式运行，每隔1000毫秒输出一次日志：

   ```
   $ GODEBUG=schedtrace=1000 ./trace 
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   Processor 处理器数量：  4
   SCHED 1003ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 0]
   SCHED 2011ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
   SCHED 3019ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
   SCHED 4027ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 0]
   ```

   以上日志的意义：
      - SCHED：调试信息输出标志字符串，代表本行是 goroutine 调度器的输出；
      - 0ms：即从程序启动到输出这行日志的时间；
      - gomaxprocs: P 的数量，本例一开始有4个 P ，后设置为 2 个 P, 因为默认的 P 的属性是和 cpu 核心数量默认一致，也可以通过 GOMAXPROCS 来设置；
      - idleprocs: 处于 idle 状态的 P 的数量；通过 gomaxprocs 和 idleprocs 的差值，就可知道执行 go 代码的 P 的数量；
      - threads: os threads/M 的数量，包含 scheduler 使用的 m 数量，加上 runtime 自用的类似 sysmon 这样的 thread 的数量；
      - spinningthreads: 处于自旋状态的 os thread 数量；
      - idlethread: 处于 idle 状态的 os thread 的数量；
      - runqueue=0： Scheduler 全局队列中 G 的数量；
      - [[1 0]]: 分别为 2 个 P 的本地队列中的 G 的数量。

   分析以上日志：
      - 一开始有4个 P ，因为我们设置了环境变量 GOMAXPROCS 为 4 ，在调用 runtime.GOMAXPROCS(2) 之后， P 的数量变为 2 ，但是 runtime.GOMAXPROCS(2) 返回值仍然为 4 ，因此 GOMAXPROCS() 设置值不是同步设置的。
      - threads 的数量与 gomaxprocs 没有绝对关系，一旦 M 阻塞了会创建新的 M ，所以可以看到 threads 大部分时候比 gomaxprocs 大。

   Debug trace 是一种查看 GMP 的方式，读者应该了解这个过程，后面不再介绍这个过程。

6. 第六步：设置 M 的最大数量
   
   创建 routineSum 协程之前先调用 ```debug.SetMaxThreads(3)``` ，这会限制最大的线程数为 4 ，再次运行：
   ```
   $ GODEBUG=schedtrace=1000 ./trace
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   runtime: program exceeds 4-thread limit
   fatal error: thread exhaustion
   ```

   可以看到 for 循环创建协程时，线程数量受限的错误。

   修改代码， SetMaxThreads 改为 5 ，创建 15 个协程：
   ```
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(2)
   	debug.SetMaxThreads(5)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   	for i := 0; i < 15; i++ {
   		go routineSum(i)
   	}
   	time.Sleep(time.Duration(5) * time.Second)
   }
   ```

   再运行，报错消失：
   ```
   $ GODEBUG=schedtrace=1000 ./trace
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   Processor 处理器数量：  4
   SCHED 1003ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=9 [0 3]
   SCHED 2011ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [5 2]
   SCHED 3019ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=7 [4 1]
   SCHED 4027ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=9 [3 0]
   ```

   经过多次测试，当 SetMaxThreads 设置比 P 的数量大，且足够协程使用时不会报错，一般不需要去修改这个值。

7. 第七步：了解 P 和 M 的创建时机

   从上面实践的日志输出可以看出，一开始 gomaxprocs 为 4 ，队列元素数量也为 4 ，当设置 GOMAXPROCS 为 2 后，gomaxprocs 变为 2 ，队列元素数量也为 2 。所以程序启动后会先以默认值（环境变量的 GOMAXPROCS 或者 CPU 核数），调用 GOMAXPROCS 设置新的有效 P 数量后会调整 P 队列。


### （二）验证调度流程
1. 第一步：编写代码，代码沿用 trace.go 并做了一些修改：
   - routineSum 函数进行超过 10 亿次以上的加法计算，这将消耗 CPU 一段时间。
   - routineSleep 函数在20秒以内随机休眠秒数。
   - 调用 trace.Start() 将 GMP 可视化数据记录到 trace.out 文件中。
   - 调用 trace.Start() 主线程休眠 2 秒，然后分批次启动 15 个 routineSum 协程和 5 个 routineSleep。

   完整代码为附录的 trace2.go 。

2. 第二步：运行代码，输出的日志在附录中，读者如果感兴趣可以自行获取。
3. 第三步：分析日志：
   1. 0ms 时刚启动， ```gomaxprocs=4 idleprocs=3 threads=2```，此时有 1 个 P 处于激活状态， 2 个 M 都处于运行状态。


---
## 总结


---
## 面试问题
1. 了解 GMP 模型吗，介绍一下？
2. 讲讲 golang 的调度模型，go 调度中阻塞都有那些方式
3. GPM 模型里如果本地队列满了，新增的 g 会怎么处理
   - 会与队列前半部分的g随机混合，然后取一半到全局队列
4. GO 语言中的协程与 Python 中的协程的区别？
5. Go 协程简单用法，goroutine的实现

---
## 提出新问题
1. 什么是锁竞争
2. 如果一个 G 阻塞了， 运行 G 的 M 也会阻塞？当有海量的 G 阻塞，也会创建海量的 M 吗

---
## 图表引用
- [1, 2, 3, 4] https://learnku.com/articles/41728

---
## 参考文档
- [Golang 调度器 GMP 原理与调度全分析](https://learnku.com/articles/41728)
- [9.2 Go 大杀器之跟踪剖析 trace](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace)
- [9.3 用 GODEBUG 看调度跟踪](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/godebug-sched)

---
## 附录
### （一）完整代码
trace.go

```
package main

import (
	"fmt"
	"runtime"
	"runtime/debug"
	"time"
)

func routineSum(n int) int {
	sum := 0
	for i := 0; i < n*10000000000; i++ {
		sum += i
	}
	return sum
}

func main() {
	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
	numProcs := runtime.GOMAXPROCS(10)
	debug.SetMaxThreads(11)
	fmt.Println("Processor 处理器数量： ", numProcs)
	for i := 0; i < 15; i++ {
		go routineSum(i)
	}
	time.Sleep(time.Duration(5) * time.Second)
}
```

trace2.go 
```
package main

import (
	"fmt"
	"math/rand"
	"os"
	"runtime"
	"runtime/trace"
	"time"
)

func routineSum(tag string, index int) int {
	fmt.Println("[Sum] begin", tag, index)
	n := rand.Intn(10)
	sum := 0
	for i := 0; i < n*100000000; i++ {
		sum += i
	}
	fmt.Println("[Sum] end", tag, index)
	return sum
}

func routineSleep(tag string, index int) {
	t := rand.Intn(20)
	fmt.Println("[Sleep] begin", tag, index, t*1000)
	time.Sleep(time.Duration(t) * time.Second)
	fmt.Println("[Sleep] end", tag, index)
}

func main() {
	runtime.GOMAXPROCS(2)
	fmt.Println("after GOMAXPROCS")

	//创建trace文件
	f, err := os.Create("trace.out")
	if err != nil {
		panic(err)
	}
	defer f.Close()

	//启动trace goroutine
	err = trace.Start(f)
	if err != nil {
		panic(err)
	}
	defer trace.Stop()

	fmt.Println("after trace.Start")
	time.Sleep(time.Duration(2) * time.Second)
	fmt.Println("after Sleep")

	for i := 0; i < 5; i++ {
		go routineSum("first", i)
	}
	for i := 0; i < 3; i++ {
		go routineSleep("first", i)
	}
	for i := 0; i < 6; i++ {
		go routineSum("second", i)
	}
	for i := 0; i < 2; i++ {
		go routineSleep("second", i)
	}
	for i := 0; i < 4; i++ {
		go routineSum("third", i)
	}
	time.Sleep(time.Duration(20) * time.Second)
}
```

### （二）日志
```
$ GODEBUG=schedtrace=300 ./trace2
SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
after GOMAXPROCS
after trace.Start
SCHED 307ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 610ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 912ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1215ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1517ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1820ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
after Sleep
[Sum] begin first 1
[Sum] begin third 3
[Sum] end third 3
[Sum] begin first 2
[Sum] begin first 3
[Sum] begin first 0
[Sum] begin first 4
[Sleep] begin first 0
[Sleep] begin first 1
[Sleep] begin first 2
[Sum] begin second 0
[Sum] begin second 1
[Sum] end second 1
[Sum] begin second 2
[Sum] begin second 3
[Sum] end second 3
[Sum] begin second 4
SCHED 2122ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 6]
[Sum] begin second 5
[Sleep] begin second 0
[Sleep] begin second 1
[Sum] begin third 0
[Sum] begin third 1
[Sum] begin third 2
SCHED 2425ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 2727ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
SCHED 3030ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 3332ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 3]
SCHED 3635ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 2]
SCHED 3938ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 3]
SCHED 4240ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 2]
SCHED 4543ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
SCHED 4845ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 5148ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
[Sum] end first 0
SCHED 5450ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 5753ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [1 4]
SCHED 6055ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
[Sleep] end first 0
SCHED 6358ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
SCHED 6660ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
SCHED 6963ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7265ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7568ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7870ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
[Sum] end first 2
SCHED 8173ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 8475ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [1 3]
SCHED 8778ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 9081ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [1 4]
SCHED 9383ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 9686ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 9989ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [2 2]
SCHED 10291ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 10594ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [1 1]
SCHED 10896ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 0]
SCHED 11199ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 11501ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [1 2]
SCHED 11804ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 2]
SCHED 12106ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 0]
SCHED 12409ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [0 4]
SCHED 12711ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 0]
[Sum] end second 4
SCHED 13014ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 1]
[Sleep] end second 1
[Sum] end third 2
SCHED 13317ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [1 2]
SCHED 13619ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [0 1]
SCHED 13922ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 0]
[Sleep] end first 2
[Sleep] end second 0
SCHED 14224ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [2 3]
SCHED 14527ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [2 2]
[Sum] end third 1
SCHED 14830ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [1 2]
SCHED 15132ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [0 1]
[Sum] end second 2
SCHED 15435ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [2 0]
SCHED 15737ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 2]
[Sum] end second 5
SCHED 16040ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [2 1]
[Sum] end second 0
SCHED 16342ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [1 1]
SCHED 16645ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
SCHED 16948ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [0 0]
SCHED 17250ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [1 1]
[Sum] end first 1
SCHED 17553ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [0 1]
SCHED 17855ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 0]
[Sum] end first 4
[Sum] end first 3
SCHED 18158ms: gomaxprocs=2 idleprocs=1 threads=5 spinningthreads=0 needspinning=0 idlethreads=2 runqueue=0 [0 0]
SCHED 18460ms: gomaxprocs=2 idleprocs=1 threads=5 spinningthreads=0 needspinning=0 idlethreads=2 runqueue=0 [0 0]
[Sum] end third 0
SCHED 18763ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19065ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19368ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19670ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19973ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20275ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20577ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20880ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
[Sleep] end first 1
SCHED 21182ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 21485ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 21787ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
```

---
