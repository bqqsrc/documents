理解Go的GMP模型（二）——Go的GMP
===

- 作者：晓白齐齐
- 更新：2024.1.11
- 声明：本文用于记录作者学习过程的心得理解，限于作者水平有限，可能存在理解错误，欢迎提出。参考文档一栏列出了本文参考的文档，本文的一些图表来自这些参考文档，如有侵权，联系作者删除，还请见谅。为避免转载导致的文章质量下降，<font color="red">本文禁止转载。</font>

---
## 一、 Go 的协程
Go 中，协程称为 goroutine ，通过关键字 go 触发。一个协程只占几 KB，这与一个线程动则 1MB 以上来说轻量了很多。 goroutine 的栈是可伸缩的，当需要更多内容时， runtime 会自动为 goroutine 分配。

goroutine 有以下两个优点：
1. 占用更小的内存。
2. 调度更灵活（runtime调度）。

---
## 二、 GMP 的各个字母代码表什么
Goroutine 的并发编程模型基于 GMP 模型，简要解释一下 GMP 的含义：

G : 表示 goroutine ，每个 goroutine 都有自己的栈空间，定时器，初始化的栈空间在 2k 左右，空间会随着需求增长。G 的集中状态：


M : 抽象化代表内核线程，记录内核线程栈信息，当 goroutine 调度到线程时，使用该 goroutine 自己的栈信息。

P : 代表调度器，负责调度 goroutine ，维护一个本地 goroutine 队列， M 从 P 上获得 goroutine 并执行，同时还负责部分内存的管理。

---
## 三、废弃的旧版协程调度器
本文不过多介绍旧版的调度器的历史，[这篇文章](https://learnku.com/articles/41728)有对旧版的调度器进行简单讲解。与其他文章一样，<span style="color: red">本文用 M 代表线程， G 代表 goroutine ， P 代表后面提到的 Processor 。</span>

<center><img src=./source/52/1.调度器符号.png width=400 float=center>

图1. 调度器符号<sup>[1]</sup></center>

<center><img src=./source/52/2.旧版调度器.png width=500 float=center>

图2. 旧版调度器<sup>[2]</sup></center>

总的来说，旧版的调度器只有 M 和 G ，存在以下几个缺点：
   1. 多个 M 通过访问全局 G 队列执行、放回 G ，需要对全局 G 队列加锁进行保护，形成了激烈的锁竞争。
   2. M 转移 G 会造成延迟和额外的系统负载，并且存在很差的局部性。例如一个 G 包含创建新的 G 的操作时，且 G 绑定在 M 的情景下， M 会创建一个新的协程 G' ， M 为了继续执行 G ，需要将 G' 交给另一个线程 M' ， M 将 G' 转移到 M' 造成了一定的延迟和系统负载。因为 G 和 G' 是相关的，所以最好将 G' 放到 M 执行而不是 M' ，所以这是较差局部性的表现。
   3. 系统调用（ CPU 在 M 之间的切换）导致频繁的线程阻塞和取消阻塞存在，造成了系统开销。

---
## 四、 GMP 模型的设计思想
### （一） Processor 处理器
新版的调度器除了 M （ thread ） 和 G （ goroutine ）， 引进了 P （ processor ） 处理器的概念。

Processor 包含运行 G 的资源，还包含了可运行的 G 队列， M 想要运行 G 需要先获取 P 。

### M 、 G 、 P
了解调度器之前，先了解这几个概念



### （二） GMP 模型
在 Go 中，协程是由线程运行的，而调度器的功能则是将可运行的协程分配到工作线程上，因此 G、 M 、 P 都是调度器的一部分，这就是 GMP 调度模型。

<center><img src=./source/52/3.新版调度器符号.png width=400 float=center>

图3. 调度器符号<sup>[3]</sup></center>

<center><img src=./source/52/4.新版调度器.jpg width=600 float=center>

图4. 新版调度器<sup>[4]</sup></center>

GMP 模型的理解： 
   1. P 列表： 程序启动时创建 P 列表，保存在数组中，最多有 GOMAXPROCS (可配置) 个 P 。
   2. 全局队列： 存放着等待运行的 G ， P 列表中的 P 都可以向全局队列获取或添加要运行的 G ，因此需要为这个全局队列加锁。
   3. P 的本地队列： 每个 P 都有一个本地 G 队列，存放着等待运行的 G ，最多不超过256个。当拥有 P 的 M 新建一个协程 G' 时，会优先将 G' 放到 P 的本地 G 队列。如果本地队列满了，会把本地队列的一半 G 移动到全局队列。
   4. M： 线程需要获取到 P ，才能从 P 中获取到等待运行的 G 。优先从 P 的本地队列获取 G ，如果 P 的本地队列为空时，则 M 会尝试从全局队列拿一批 G 放到 P 的本地队列，如果从全局队列获取不到 G ，则从其他的 P 的本地队列偷一半到自己 P 的本地队里。 M 拿到 G 后执行，执行完拿到的 G 后，从 P 获取下一个 G ，如此重复。执行过程中如果生成新的协程 G' ，则将 G' 优先放到自己的 P 的本地队列，当自己的 P 的本地队列满了，则移动一半 G 到全局队列。

以上是 GMP 调度器的模型， GMP 调度器通过 M 连接 操作系统调度器， OS 调度器负责将内核线程分配到 CPU 核运行。

### （三） P 和 M 的个数和创建时机
1. P 的数量由环境变量 $GOMAXPROCS 或者 runtime 的方法 GOMAXPROCS() 的返回值决定。同一时刻至多只有 GOMAXPROCS 个 goroutine 在同时运行。
2. P 的数量取值顺序，先使用 GOMAXPROCS() 设置的值，如果 GOMAXPROCS() 没有设置，先取环境变量 $GOMAXPROCS 的值，环境变量没有设置有效值，默认为 CPU 核数。
3. M 的数量由 runtime/debug 中的 SetMaxThreads 函数决定，该函数设置了 M 的最大数量， go 程序启动后会默认设置 M 的最大数量为 10000 。如果 SetMaxThreads 的值设置过低，有可能会报线程数量受限的错误。
4. M 与 P 没有决定关系，一个 M 阻塞， P 就会去创建或者切换到另一个 M ，所以 P 的默认数量为1，也可能会创建很多个 M 出来。
5. P 何时创建：程序运行时，先创建默认数量 GOMAXPROCS 的 P 队列，如果调用了 GOMAXPROCS 设置了新的 P 最大数量 n 后，运行时系统会根据这个数量 n 调整 P 队列。
6. M 何时创建：没有足够的 M 来关联 P 运行其中可运行的 G ，会创建 M 。如果所有的 M 都阻塞了，而 P 中还有很多就绪任务，就会寻找空闲的 M ，没有空闲的 M ，就会创建新的 M 。如果 M 的数量较少无法将所有的 P 都对应进行处理，且有新的就绪的 G 时，也会创建新的 M 。

### （四） GMP 的调度策略

### （五） GMP 的调度流程

### （六） GMP 的生命周期

---
## 五、新版的 MGP 模型有哪些改进

---
## 五、 GMP 的调度分析工具
可以通过两种方式可以查看程序的 GMP 数据：
   1. go tool trace 
   2. Debug trace

本节不专门讲解用 Debug trace 方法查看 GMP 数据的过程，因为作者在本文的第五节的验证过程中写了，不在这里重复写，读者可以跟着第五节一起敲下代码，相信应该就清楚如何使用了。读者也可以阅读[这篇文章](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/godebug-sched#godebug)了解。

### go tool trace 的使用
本节简单介绍一下 trace 的使用，实际上 trace 能看的信息很多，读者可以阅读[这篇文章](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace)学习更多使用 trace 的使用。

1. 第一步：创建项目，编写代码，调用 trace.Start ，将trace 数据保存到文件。

2. 第二步：运行程序。

3. 第三步：打开记录轨迹的文件（假设文件名为 trace.out ）。

   trace.out 文件记录了程序运行过程中 GMP 可视化的数据，这个文件是个二进制文件，可以使用 go tool trace 打开分析：
   
   ```
   $ go tool trace trace.out
   2024/01/10 19:13:26 Parsing trace...
   2024/01/10 19:13:26 Splitting trace...
   2024/01/10 19:13:26 Opening browser. Trace viewer is listening on http://127.0.0.1:10966 
   ```

   此时可以通过打开浏览器 ```http://127.0.0.1:10966``` 网址，点击 ```view trace``` 查看程序的 GMP 调度流程，网址的端口不是固定的，在运行 ```go tool trace trace.out``` 输出的最后一行可以看到。

   可以看到 GMP 调度可视化图：
   
   <center><img src=./source/52/5.GMP可视化界面.png width=1200 float=center>

   图5. GMP可视化界面</center>

   点击右上角的 ```Flow events``` 按钮，勾选 All ，可以显示发生的事件。如下图所示：
   
   <center><img src=./source/52/6.可视化界面显示event.png width=400 float=center>

   图6. 可视化界面显示event</center>

4. 第四步：了解可视化 GMP 信息界面的使用。
   
   可视化界面的 x 轴表示程序启动运行的时间， y 轴为各项 GMP 数据。

   <center><img src=./source/52/7.GMP可视化x.y轴.png width=600 float=center>

   图7. GMP可视化x.y轴</center>

   在界面的右方有一个工具栏，可以用于缩放坐标轴的比例、移动坐标轴、选择某一范围。

   <center><img src=./source/52/8.GMP可视化工具栏.png width=500 float=center>

   图8. GMP可视化工具栏</center>

---
## 六、GMP 模型分析过程中的代码验证
本节主要为作者自己进行的验证，读者可以直接跳过，也可以跟着一起敲下代码。完整代码在本文的附录中可以获取。

### （一）验证 P 和 M 的个数和创建时机
1. 第一步： 创建一个项目，运行下面的代码：

   文件 trace.go :
   ```
   package main
   
   import (
   	"fmt"
   	"runtime"
   )
   
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(0)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   }
   ```
   
   运行：
   ```
   $ go run trace.go
   CPU 核心数量：  8
   Processor 处理器数量：  8
   ```
   
   这段代码调用 runtime.NumCPU() 输出了机器的 CPU 核心数，调用 runtime.GOMAXPROCS(0) 获取 P 的数量。通过结果可知没有设置 GOMAXPROCS 的值时默认 P 的数量为 CPU 核心数。
   
   这里的 CPU 核心数量是指机器的逻辑处理器的数量，而不是物理内核数，windows 系统下可以在 任务管理器->性能->CPU 查看到自己机器的内核数和逻辑处理器数量，这里不展开。

2. 第二步： 添加环境变量。
   给机器添加一个环境变量 GOMAXPROCS ，设置为 4 ，环境变量如何设置这里不展开，再运行程序：
   ```
   go run trace.go
   CPU 核心数量：  8
   Processor 处理器数量：  4
   ```
   
   此时 P 的数量变为 4 ，虽然 CPU 核心数量为 8 。
   
3. 第三步：GOMAXPROCS 设置具体 P数量。
   将 runtime.GOMAXPROCS(0) 改为 runtime.GOMAXPROCS(2)，运行程序，得到的结果还是4。一开始作者以为是优先取环境变量 GOMAXPROCS ，所以将环境变量删除，再运行，得到的结果是 8 ，调试之后发现 runtime.GOMAXPROCS() 传入的 n 直接就是 0 ，而不是传入的 2 。经过多番调试都没有得到理论上的 0 。作者以为是系统环境问题，便搭建了一个 Docker 环境测试，结果也不符合预期。
   
   作者起初也百思不得其解，认为是机器问题吧，到后面的步骤之后，才解了这个谜团。

4. 第四步：创建n一个长时间执行的协程。
   添加如下代码：
   ```
   func routineSum(n int) int {
   	sum := 0
   	for i := 0; i < n*10000000000; i++ {
   		sum += i
   	}
   	return sum
   }
   ```

   这个函数进行上百亿次加法运算，有一定的耗时。

   main 函数中启动 n 个协程：
   ```
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(2)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   	for i := 0; i < 5; i++ {
   		go routineSum(i)
   	}
      time.Sleep(time.Duration(5) * time.Second)
   }
   ```

   这段代码将会启动 5 个耗时较长的计算，并且主线程睡眠 5 秒。

5. 第五步：使用 Debug trace 来查看 P 和 M 的情况。

   编译:
   ```
   $ go build trace.go 
   ```

   通过 Debug 方式运行，每隔1000毫秒输出一次日志：

   ```
   $ GODEBUG=schedtrace=1000 ./trace 
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   Processor 处理器数量：  4
   SCHED 1003ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 0]
   SCHED 2011ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
   SCHED 3019ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
   SCHED 4027ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 0]
   ```

   以上日志的意义：
      - SCHED：调试信息输出标志字符串，代表本行是 goroutine 调度器的输出；
      - 0ms：即从程序启动到输出这行日志的时间；
      - gomaxprocs: P 的数量，本例一开始有4个 P ，后设置为 2 个 P, 因为默认的 P 的属性是和 cpu 核心数量默认一致，也可以通过 GOMAXPROCS 来设置；
      - idleprocs: 处于 idle 状态的 P 的数量；通过 gomaxprocs 和 idleprocs 的差值，就可知道执行 go 代码的 P 的数量；
      - threads: os threads/M 的数量，包含 scheduler 使用的 m 数量，加上 runtime 自用的类似 sysmon 这样的 thread 的数量；
      - spinningthreads: 处于自旋状态的 os thread 数量；
      - idlethread: 处于 idle 状态的 os thread 的数量；
      - runqueue=0： Scheduler 全局队列中 G 的数量；
      - [[1 0]]: 分别为 2 个 P 的本地队列中的 G 的数量。

   分析以上日志：
      - 一开始有4个 P ，因为我们设置了环境变量 GOMAXPROCS 为 4 ，在调用 runtime.GOMAXPROCS(2) 之后， P 的数量变为 2 ，但是 runtime.GOMAXPROCS(2) 返回值仍然为 4 ，因此 GOMAXPROCS() 设置值不是同步设置的。
      - threads 的数量与 gomaxprocs 没有绝对关系，一旦 M 阻塞了会创建新的 M ，所以可以看到 threads 大部分时候比 gomaxprocs 大。

   Debug trace 是一种查看 GMP 的方式，读者应该了解这个过程，后面不再介绍这个过程。

6. 第六步：设置 M 的最大数量
   
   创建 routineSum 协程之前先调用 ```debug.SetMaxThreads(3)``` ，这会限制最大的线程数为 4 ，再次运行：
   ```
   $ GODEBUG=schedtrace=1000 ./trace
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   runtime: program exceeds 4-thread limit
   fatal error: thread exhaustion
   ```

   可以看到 for 循环创建协程时，线程数量受限的错误。

   修改代码， SetMaxThreads 改为 5 ，创建 15 个协程：
   ```
   func main() {
   	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
   	numProcs := runtime.GOMAXPROCS(2)
   	debug.SetMaxThreads(5)
   	fmt.Println("Processor 处理器数量： ", numProcs)
   	for i := 0; i < 15; i++ {
   		go routineSum(i)
   	}
   	time.Sleep(time.Duration(5) * time.Second)
   }
   ```

   再运行，报错消失：
   ```
   $ GODEBUG=schedtrace=1000 ./trace
   SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
   CPU 核心数量：  8
   Processor 处理器数量：  4
   SCHED 1003ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=9 [0 3]
   SCHED 2011ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [5 2]
   SCHED 3019ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=7 [4 1]
   SCHED 4027ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=9 [3 0]
   ```

   经过多次测试，当 SetMaxThreads 设置比 P 的数量大，且足够协程使用时不会报错，一般不需要去修改这个值。

7. 第七步：了解 P 和 M 的创建时机

   从上面实践的日志输出可以看出，一开始 gomaxprocs 为 4 ，队列元素数量也为 4 ，当设置 GOMAXPROCS 为 2 后，gomaxprocs 变为 2 ，队列元素数量也为 2 。所以程序启动后会先以默认值（环境变量的 GOMAXPROCS 或者 CPU 核数），调用 GOMAXPROCS 设置新的有效 P 数量后会调整 P 队列。


### （二）验证调度流程
1. 第一步：编写代码，代码沿用 trace.go 并做了一些修改：
   - routineSum 函数进行超过 10 亿次以上的加法计算，这将消耗 CPU 一段时间。
   - routineSleep 函数在20秒以内随机休眠秒数。
   - 调用 trace.Start() 将 GMP 可视化数据记录到 trace.out 文件中。
   - 调用 trace.Start() 主线程睡眠 2 秒，然后分批次启动 15 个 routineSum 协程和 5 个 routineSleep。

   完整代码为附录的 trace2.go 。

2. 第二步：运行代码，输出的日志在附录中，读者如果感兴趣可以自行获取。
3. 第三步：分析日志：
   1. 0ms 时刚启动， ```gomaxprocs=4 idleprocs=3 threads=2```，此时有 1 个 P 处于激活状态， 2 个 M 都处于运行状态。


---
## 总结


---
## 面试问题
1. 了解 GMP 模型吗，介绍一下？
2. 讲讲 golang 的调度模型，go 调度中阻塞都有那些方式
3. GPM 模型里如果本地队列满了，新增的 g 会怎么处理
   - 会与队列前半部分的g随机混合，然后取一半到全局队列
4. GO 语言中的协程与 Python 中的协程的区别？
5. Go 协程简单用法，goroutine的实现

---
## 提出新问题
1. 什么是锁竞争
2. 如果一个 G 阻塞了， 运行 G 的 M 也会阻塞？当有海量的 G 阻塞，也会创建海量的 M 吗

---
## 图表引用
- [1, 2, 3, 4] https://learnku.com/articles/41728

---
## 参考文档
- [Golang 调度器 GMP 原理与调度全分析](https://learnku.com/articles/41728)
- [9.2 Go 大杀器之跟踪剖析 trace](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/go-tool-trace)
- [9.3 用 GODEBUG 看调度跟踪](https://eddycjy.gitbook.io/golang/di-9-ke-gong-ju/godebug-sched)

---
## 附录
### （一）完整代码
trace.go

```
package main

import (
	"fmt"
	"runtime"
	"runtime/debug"
	"time"
)

func routineSum(n int) int {
	sum := 0
	for i := 0; i < n*10000000000; i++ {
		sum += i
	}
	return sum
}

func main() {
	fmt.Println("CPU 核心数量： ", runtime.NumCPU())
	numProcs := runtime.GOMAXPROCS(10)
	debug.SetMaxThreads(11)
	fmt.Println("Processor 处理器数量： ", numProcs)
	for i := 0; i < 15; i++ {
		go routineSum(i)
	}
	time.Sleep(time.Duration(5) * time.Second)
}
```

trace2.go 
```
package main

import (
	"fmt"
	"math/rand"
	"os"
	"runtime"
	"runtime/trace"
	"time"
)

func routineSum(tag string, index int) int {
	fmt.Println("[Sum] begin", tag, index)
	n := rand.Intn(10)
	sum := 0
	for i := 0; i < n*100000000; i++ {
		sum += i
	}
	fmt.Println("[Sum] end", tag, index)
	return sum
}

func routineSleep(tag string, index int) {
	t := rand.Intn(20)
	fmt.Println("[Sleep] begin", tag, index, t*1000)
	time.Sleep(time.Duration(t) * time.Second)
	fmt.Println("[Sleep] end", tag, index)
}

func main() {
	runtime.GOMAXPROCS(2)
	fmt.Println("after GOMAXPROCS")

	//创建trace文件
	f, err := os.Create("trace.out")
	if err != nil {
		panic(err)
	}
	defer f.Close()

	//启动trace goroutine
	err = trace.Start(f)
	if err != nil {
		panic(err)
	}
	defer trace.Stop()

	fmt.Println("after trace.Start")
	time.Sleep(time.Duration(2) * time.Second)
	fmt.Println("after Sleep")

	for i := 0; i < 5; i++ {
		go routineSum("first", i)
	}
	for i := 0; i < 3; i++ {
		go routineSleep("first", i)
	}
	for i := 0; i < 6; i++ {
		go routineSum("second", i)
	}
	for i := 0; i < 2; i++ {
		go routineSleep("second", i)
	}
	for i := 0; i < 4; i++ {
		go routineSum("third", i)
	}
	time.Sleep(time.Duration(20) * time.Second)
}
```

### （二）日志
```
$ GODEBUG=schedtrace=300 ./trace2
SCHED 0ms: gomaxprocs=4 idleprocs=3 threads=2 spinningthreads=0 needspinning=0 idlethreads=0 runqueue=0 [0 0 0 0]
after GOMAXPROCS
after trace.Start
SCHED 307ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 610ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 912ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1215ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1517ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 1820ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
after Sleep
[Sum] begin first 1
[Sum] begin third 3
[Sum] end third 3
[Sum] begin first 2
[Sum] begin first 3
[Sum] begin first 0
[Sum] begin first 4
[Sleep] begin first 0
[Sleep] begin first 1
[Sleep] begin first 2
[Sum] begin second 0
[Sum] begin second 1
[Sum] end second 1
[Sum] begin second 2
[Sum] begin second 3
[Sum] end second 3
[Sum] begin second 4
SCHED 2122ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 6]
[Sum] begin second 5
[Sleep] begin second 0
[Sleep] begin second 1
[Sum] begin third 0
[Sum] begin third 1
[Sum] begin third 2
SCHED 2425ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 2727ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
SCHED 3030ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 3332ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 3]
SCHED 3635ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 2]
SCHED 3938ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 3]
SCHED 4240ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 2]
SCHED 4543ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
SCHED 4845ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [4 3]
SCHED 5148ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 4]
[Sum] end first 0
SCHED 5450ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 5753ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [1 4]
SCHED 6055ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
[Sleep] end first 0
SCHED 6358ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
SCHED 6660ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [3 0]
SCHED 6963ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7265ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7568ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
SCHED 7870ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 1]
[Sum] end first 2
SCHED 8173ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 8475ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [1 3]
SCHED 8778ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 9081ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [1 4]
SCHED 9383ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 9686ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 9989ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [2 2]
SCHED 10291ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=8 [0 0]
SCHED 10594ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=6 [1 1]
SCHED 10896ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 0]
SCHED 11199ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [2 1]
SCHED 11501ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [1 2]
SCHED 11804ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 2]
SCHED 12106ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [3 0]
SCHED 12409ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [0 4]
SCHED 12711ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [4 0]
[Sum] end second 4
SCHED 13014ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 1]
[Sleep] end second 1
[Sum] end third 2
SCHED 13317ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [1 2]
SCHED 13619ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=5 [0 1]
SCHED 13922ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=3 [3 0]
[Sleep] end first 2
[Sleep] end second 0
SCHED 14224ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [2 3]
SCHED 14527ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [2 2]
[Sum] end third 1
SCHED 14830ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [1 2]
SCHED 15132ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=4 [0 1]
[Sum] end second 2
SCHED 15435ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [2 0]
SCHED 15737ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [1 2]
[Sum] end second 5
SCHED 16040ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [2 1]
[Sum] end second 0
SCHED 16342ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [1 1]
SCHED 16645ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 1]
SCHED 16948ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=2 [0 0]
SCHED 17250ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [1 1]
[Sum] end first 1
SCHED 17553ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=0 [0 1]
SCHED 17855ms: gomaxprocs=2 idleprocs=0 threads=5 spinningthreads=0 needspinning=1 idlethreads=2 runqueue=1 [0 0]
[Sum] end first 4
[Sum] end first 3
SCHED 18158ms: gomaxprocs=2 idleprocs=1 threads=5 spinningthreads=0 needspinning=0 idlethreads=2 runqueue=0 [0 0]
SCHED 18460ms: gomaxprocs=2 idleprocs=1 threads=5 spinningthreads=0 needspinning=0 idlethreads=2 runqueue=0 [0 0]
[Sum] end third 0
SCHED 18763ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19065ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19368ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19670ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 19973ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20275ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20577ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 20880ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
[Sleep] end first 1
SCHED 21182ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 21485ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
SCHED 21787ms: gomaxprocs=2 idleprocs=2 threads=5 spinningthreads=0 needspinning=0 idlethreads=3 runqueue=0 [0 0]
```

---
